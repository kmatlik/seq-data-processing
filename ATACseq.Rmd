---
title: "ATACseq"
author: "Kärt Mätlik"
date: "2024-10-10"
output: html_document
---

ATACseq read processing and mapping (paired-end samples)

# Load libraries
```{r setup, include=FALSE}
library(Rfastp)
library(Rsubread)
library(Rsamtools)
library(tidyverse)
library(magrittr)
library(Herper)
```

# Set up files & directories
```{r}
read_1 <- c("R1_001.fastq.gz", "R1_002.fastq.gz", "R1_003.fastq.gz")
read_2 <- c("R2_001.fastq.gz", "R2_002.fastq.gz", "R2_003.fastq.gz")
outputdir <- "C:/Users/kvare/Documents/Seq/ATAC/"
samplelist <- c("sample1", "sample2", "sample3")
ref_genome <- "C:/Users/kvare/Documents/Seq/RefGenome/mm10_mainchrs"
```

# Quality control & trimming
```{r}
for(i in 1:length(samplelist)){
  qc_report <- rfastp(
    read1 = read_1[i],
    read2 = read_2[i],
    outputFastq = paste0(outputdir, samplelist[i])
  )
}
```

# Mapping to reference genome
```{r}
for(i in 1:length(samplelist)){
  
  # Align to reference genome
  mapping_report <- align(index = ref_genome,
                             readfile1 = paste0(outputdir, samplelist[i], "_R1.fastq.gz"),
                             readfile2 = paste0(outputdir, samplelist[i], "_R2.fastq.gz"),
                             output_format = "BAM",
                             output_file = paste0(outputdir, samplelist[i], ".bam"), 
                             type = "dna",
                             phredOffset = 33, 
                             nthreads = 8,
                             unique = TRUE,
                             maxFragLength = 2000)
  mapping_report %>% write.table(paste0(outputdir, samplelist[i], "_mapping_summary.csv"))
  
  # Sort BAM
  sortBam(file = paste0(outputdir, samplelist[i], ".bam"), 
          destination = paste0(outputdir, samplelist[i], "_sorted"))
  
  # Remove unsorted bam file to save space
  file.remove(paste0(outputdir, samplelist[i], ".bam"))
}
```

# Remove duplicates and call peaks
```{r, eval = F}
# Move files to picard/data
cd picard

# Run the following for each sample.

# Define read groups in bam files using picard. See https://gatk.broadinstitute.org/hc/en-us/articles/360035890671-Read-groups for details
java -jar build/libs/picard.jar AddOrReplaceReadGroups \
      I=data/sample1_sorted.bam \
      O=data/sample1_with_RG.bam \
      RGID=1 \
      RGLB=lib1 \
      RGPL=illumina \
      RGPU=unit1 \
      RGSM=1

# Mark duplicates
java -jar build/libs/picard.jar MarkDuplicates \
--INPUT data/sample1_with_RG.bam --OUTPUT data/sample1_deduplicated.bam --METRICS_FILE data/sample1_metrics.txt --REMOVE_DUPLICATES true


# Peak calling with macs3 (paired end mode)
macs3 callpeak -t picard/data/sample1_deduplicated.bam -n sample1 -f BAMPE --outdir data/macs3_callpeak -g mm 

# Move files back to outputdir.
# Delete _sorted.bam and _with_RG.bam files.
```

# Index BAMs
```{r}
for(i in 1:length(samplelist)){
  indexBam(paste0(outputdir, samplelist[i], "_deduplicated.bam"))
}
```

# Create bigwigs
```{r}
for(i in 1:length(samplelist)){
  # Mapping summary over chromosomes
  mapped_stats <- idxstatsBam(paste0(outputdir, samplelist[i], "_deduplicated.bam"))
  mapped_stats %>% write_csv(paste0(outputdir, samplelist[i], "_mapped_stats.csv"))
  
  # Create bigwig files
  read_coverage <- coverage(paste0(outputdir, samplelist[i], "_deduplicated.bam"),
                            weight = (10^6)/sum(mapped_stats[,"mapped"]))
  export.bw(read_coverage, paste0(outputdir, samplelist[i], ".bw"))
}
```
